# Impl√©mentation de Micrograd avec un test de classification

Ce projet est une impl√©mentation de **Micrograd**, un framework minimaliste pour le calcul des gradients automatiques, r√©alis√© √† l'aide du tutoriel d'Andrej Karpathy : https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ <br><br>
L'objectif est de comprendre en profondeur les concepts fondamentaux du **forward pass**, de la **r√©tropropagation** (backward pass), et de leur application dans un r√©seau de neurones.

---

## üß† Micrograd

Micrograd est un framework simple pour le calcul automatique des gradients (autograd) gr√¢ce √† la construction d'un graphe. Chaque op√©ration est enregistr√©e dans ce graphe, permettant de calculer les d√©riv√©es n√©cessaires pour l'optimisation des param√®tres dans un mod√®le d'apprentissage automatique.

Les concepts abord√©s dans ce projet incluent :
- Les passes avant et arri√®re (forward et backward pass).
- La construction d'un r√©seau neuronal simple (MLP - Multi-Layer Perceptron).
- L'apprentissage supervis√© avec des donn√©es artificielles.
- Une application √† une t√¢che de classification binaire.

---

## üìÅ Structure 

Le notebook contient plusieurs sections :
1. **Recr√©ation de Micrograd :** D√©veloppement de la classe `Value` pour repr√©senter des scalaires avec des gradients.
2. **Construction d'un r√©seau neuronal :** Cr√©ation des classes `Neuron`, `Layer` et `MLP` pour mod√©liser un perceptron multicouche.
3. **Test de classification :** Application √† une t√¢che simple de classification binaire avec des donn√©es artificielles.
4. **Visualisation des r√©sultats :** Affichage de la fronti√®re de d√©cision du mod√®le.


---

## üñºÔ∏è Visualisation

Voici une visualisation de la fronti√®re de d√©cision du mod√®le apr√®s l'entra√Ænement :

![Fronti√®re de d√©cision](https://github.com/user-attachments/assets/6dc0d339-9e88-4728-8786-c9c5ad22a514)

---
